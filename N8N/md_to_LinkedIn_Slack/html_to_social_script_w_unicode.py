#!/usr/bin/env python3
"""
HTML Email to Social Media Post Converter
Extracts content from HTML emails and formats for LinkedIn/Facebook posting
"""

import os
import re
import glob
from bs4 import BeautifulSoup
from pathlib import Path
import argparse

class EmailToSocialConverter:
    def __init__(self):
        # Emoji mappings for different pain points/benefits
        self.emoji_map = {
            'production': 'ğŸ”¥',
            'fire': 'ğŸ”¥',
            'bugs': 'ğŸ›',
            'balance': 'âš–ï¸',
            'feature': 'âš–ï¸',
            'documentation': 'ğŸ“',
            'docs': 'ğŸ“',
            'knowledge': 'ğŸ§ ',
            'blind': 'ğŸ¤”',
            'confused': 'ğŸ¤”',
            'monitoring': 'ğŸ“Š',
            'test': 'âœ…',
            'coverage': 'âœ…',
            'confidence': 'âœ…',
            'deploy': 'ğŸš€',
            'automation': 'ğŸ¤–',
            'ai': 'ğŸ¤–',
            'growth': 'ğŸ“ˆ',
            'startup': 'ğŸš€',
            'scale': 'ğŸ“ˆ'
        }
        
        # Unicode character mappings for formatting
        self.unicode_chars = {
            'bold': {
                'a': 'ğ—®', 'b': 'ğ—¯', 'c': 'ğ—°', 'd': 'ğ—±', 'e': 'ğ—²', 'f': 'ğ—³', 'g': 'ğ—´', 'h': 'ğ—µ',
                'i': 'ğ—¶', 'j': 'ğ—·', 'k': 'ğ—¸', 'l': 'ğ—¹', 'm': 'ğ—º', 'n': 'ğ—»', 'o': 'ğ—¼', 'p': 'ğ—½',
                'q': 'ğ—¾', 'r': 'ğ—¿', 's': 'ğ˜€', 't': 'ğ˜', 'u': 'ğ˜‚', 'v': 'ğ˜ƒ', 'w': 'ğ˜„', 'x': 'ğ˜…',
                'y': 'ğ˜†', 'z': 'ğ˜‡', 'A': 'ğ—”', 'B': 'ğ—•', 'C': 'ğ—–', 'D': 'ğ——', 'E': 'ğ—˜', 'F': 'ğ—™',
                'G': 'ğ—š', 'H': 'ğ—›', 'I': 'ğ—œ', 'J': 'ğ—', 'K': 'ğ—', 'L': 'ğ—Ÿ', 'M': 'ğ— ', 'N': 'ğ—¡',
                'O': 'ğ—¢', 'P': 'ğ—£', 'Q': 'ğ—¤', 'R': 'ğ—¥', 'S': 'ğ—¦', 'T': 'ğ—§', 'U': 'ğ—¨', 'V': 'ğ—©',
                'W': 'ğ—ª', 'X': 'ğ—«', 'Y': 'ğ—¬', 'Z': 'ğ—­', '0': 'ğŸ¬', '1': 'ğŸ­', '2': 'ğŸ®', '3': 'ğŸ¯',
                '4': 'ğŸ°', '5': 'ğŸ±', '6': 'ğŸ²', '7': 'ğŸ³', '8': 'ğŸ´', '9': 'ğŸµ'
            },
            'italic': {
                'a': 'ğ˜¢', 'b': 'ğ˜£', 'c': 'ğ˜¤', 'd': 'ğ˜¥', 'e': 'ğ˜¦', 'f': 'ğ˜§', 'g': 'ğ˜¨', 'h': 'ğ˜©',
                'i': 'ğ˜ª', 'j': 'ğ˜«', 'k': 'ğ˜¬', 'l': 'ğ˜­', 'm': 'ğ˜®', 'n': 'ğ˜¯', 'o': 'ğ˜°', 'p': 'ğ˜±',
                'q': 'ğ˜²', 'r': 'ğ˜³', 's': 'ğ˜´', 't': 'ğ˜µ', 'u': 'ğ˜¶', 'v': 'ğ˜·', 'w': 'ğ˜¸', 'x': 'ğ˜¹',
                'y': 'ğ˜º', 'z': 'ğ˜»', 'A': 'ğ˜ˆ', 'B': 'ğ˜‰', 'C': 'ğ˜Š', 'D': 'ğ˜‹', 'E': 'ğ˜Œ', 'F': 'ğ˜',
                'G': 'ğ˜', 'H': 'ğ˜', 'I': 'ğ˜', 'J': 'ğ˜‘', 'K': 'ğ˜’', 'L': 'ğ˜“', 'M': 'ğ˜”', 'N': 'ğ˜•',
                'O': 'ğ˜–', 'P': 'ğ˜—', 'Q': 'ğ˜˜', 'R': 'ğ˜™', 'S': 'ğ˜š', 'T': 'ğ˜›', 'U': 'ğ˜œ', 'V': 'ğ˜',
                'W': 'ğ˜', 'X': 'ğ˜Ÿ', 'Y': 'ğ˜ ', 'Z': 'ğ˜¡'
            }
        }
    
    def extract_content(self, html_file):
        """Extract key content sections from HTML email"""
        with open(html_file, 'r', encoding='utf-8') as f:
            soup = BeautifulSoup(f.read(), 'html.parser')
        
        content = {
            'subject': '',
            'hook': '',
            'stats': [],
            'pain_points': [],
            'features': [],
            'quote': '',
            'cta': '',
            'hashtags': []
        }
        
        # Extract subject/main headline
        hero_h1 = soup.find('h1')
        if hero_h1:
            content['subject'] = hero_h1.get_text().strip()
        
        # Extract hook (first paragraph after headline)
        hero_p = soup.find('div', class_='hero')
        if hero_p:
            p_tag = hero_p.find('p')
            if p_tag:
                content['hook'] = p_tag.get_text().strip()
        
        # Extract stats
        stats = soup.find_all('div', class_='stat-item')
        for stat in stats:
            number = stat.find('span', class_='stat-number')
            label = stat.find('div', class_='stat-label')
            if number and label:
                content['stats'].append({
                    'number': number.get_text().strip(),
                    'label': label.get_text().strip()
                })
        
        # Extract pain points
        pain_points = soup.find_all('div', class_='pain-point')
        for pain in pain_points:
            title = pain.find('div', class_='pain-title')
            desc = pain.find('div', class_='pain-desc')
            if title and desc:
                content['pain_points'].append({
                    'title': title.get_text().strip(),
                    'description': desc.get_text().strip()
                })
        
        # Extract features
        features = soup.find_all('div', class_='feature-item')
        for feature in features:
            title = feature.find('div', class_='feature-title')
            desc = feature.find('div', class_='feature-desc')
            if title and desc:
                content['features'].append({
                    'title': title.get_text().strip(),
                    'description': desc.get_text().strip()
                })
        
        # Extract quote
        quote_text = soup.find('div', class_='quote-text')
        quote_author = soup.find('div', class_='quote-author')
        if quote_text:
            content['quote'] = quote_text.get_text().strip()
            if quote_author:
                content['quote'] += f" - {quote_author.get_text().strip()}"
        
        # Extract CTA
        cta_button = soup.find('a', class_='cta-button')
        if cta_button:
            content['cta'] = cta_button.get_text().strip()
        
        return content
    
    def to_unicode_bold(self, text):
        """Convert text to Unicode bold characters"""
        result = ""
        for char in text:
            result += self.unicode_chars['bold'].get(char, char)
        return result
    
    def to_unicode_italic(self, text):
        """Convert text to Unicode italic characters"""
        result = ""
        for char in text:
            result += self.unicode_chars['italic'].get(char, char)
        return result
    
    def add_emoji(self, text):
        """Add relevant emoji based on text content"""
        text_lower = text.lower()
        for keyword, emoji in self.emoji_map.items():
            if keyword in text_lower:
                return f"{emoji} {text}"
        return f"â€¢ {text}"  # Default bullet if no emoji match
    
    def format_for_social(self, content):
        """Format extracted content for LinkedIn/Facebook posting (with Unicode formatting)"""
        
        # Start with hook
        post = f"{self.to_unicode_bold(self.add_emoji(content['subject']))}\n\n"
        
        if content['hook']:
            # Break hook into short lines for mobile readability
            hook_lines = content['hook'].split('. ')
            for line in hook_lines:
                if line.strip():
                    post += f"{line.strip()}{'.' if not line.endswith('.') else ''}\n\n"
        
        # Add stats if available
        if content['stats']:
            post += f"{self.to_unicode_bold('Here\\'s what\\'s possible:')}\n\n"
            for stat in content['stats']:
                post += f"âœ… {self.to_unicode_bold(stat['number'] + ' ' + stat['label'].lower())}\n"
            post += "\n"
        
        # Add pain points
        if content['pain_points']:
            post += f"{self.to_unicode_bold('The challenge:')}\n\n"
            for i, pain in enumerate(content['pain_points'][:3]):  # Limit to 3 for readability
                emoji_title = self.add_emoji(pain['title'])
                post += f"{emoji_title} - {pain['description']}\n\n"
        
        # Add features/benefits
        if content['features']:
            post += f"{self.to_unicode_bold('The solution:')}\n\n"
            for feature in content['features'][:3]:  # Limit to 3
                emoji_title = self.add_emoji(feature['title'])
                post += f"âœ… {self.to_unicode_bold(emoji_title)} - {feature['description']}\n\n"
        
        # Add quote if available
        if content['quote']:
            post += f"{self.to_unicode_bold('What others say:')}\n\n{self.to_unicode_italic('\"' + content['quote'] + '\"')}\n\n"
        
        # Add CTA
        if content['cta']:
            post += f"{self.to_unicode_bold(content['cta'])}\n\n"
            post += "Link in comments ğŸ‘‡\n\n"
        
        # Add engagement hook
        post += "What's your experience with this? Share below!\n\n"
        
        # Add hashtags
        hashtags = self.generate_hashtags(content)
        post += " ".join(hashtags)
        
        return post
    
    def generate_hashtags(self, content):
        """Generate relevant hashtags based on content"""
        base_hashtags = ["#StartupLife", "#TechLeadership", "#ProductDevelopment"]
        
        # Add context-specific hashtags
        text_content = f"{content['subject']} {content['hook']}".lower()
        
        if 'production' in text_content or 'fire' in text_content:
            base_hashtags.append("#ProductionIssues")
        if 'tech debt' in text_content or 'debt' in text_content:
            base_hashtags.append("#TechDebt")
        if 'cto' in text_content or 'engineering' in text_content:
            base_hashtags.append("#StartupCTO")
        if 'ai' in text_content or 'automation' in text_content:
            base_hashtags.append("#AITools")
        if 'test' in text_content or 'coverage' in text_content:
            base_hashtags.append("#SoftwareTesting")
        
        return base_hashtags[:8]  # LinkedIn recommends 3-5, but up to 8 is fine
    
    def process_folder(self, folder_path, output_folder=None):
        """Process all HTML files in a folder"""
        folder_path = Path(folder_path)
        if output_folder:
            output_folder = Path(output_folder)
            output_folder.mkdir(exist_ok=True)
        else:
            output_folder = folder_path / "social_posts"
            output_folder.mkdir(exist_ok=True)
        
        html_files = glob.glob(str(folder_path / "*.html"))
        
        for html_file in html_files:
            print(f"Processing: {html_file}")
            
            try:
                content = self.extract_content(html_file)
                social_post = self.format_for_social(content)
                
                # Save to output file
                output_file = output_folder / f"{Path(html_file).stem}_social_post.txt"
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(social_post)
                
                print(f"âœ… Generated: {output_file}")
                
            except Exception as e:
                print(f"âŒ Error processing {html_file}: {e}")

def main():
    parser = argparse.ArgumentParser(description="Convert HTML emails to social media posts")
    parser.add_argument("input_folder", help="Folder containing HTML email files")
    parser.add_argument("-o", "--output", help="Output folder for social posts (default: input_folder/social_posts)")
    parser.add_argument("-f", "--file", help="Process single file instead of folder")
    
    args = parser.parse_args()
    
    converter = EmailToSocialConverter()
    
    if args.file:
        # Process single file
        content = converter.extract_content(args.file)
        social_post = converter.format_for_social(content)
        print(social_post)
    else:
        # Process folder
        converter.process_folder(args.input_folder, args.output)

if __name__ == "__main__":
    main()
